{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Statistical Analysis: ANOVA with Tukey HSD\n\nThis notebook performs statistical analysis to compare the performance of different driver identification algorithms using ANOVA and Tukey's Honestly Significant Difference (HSD) test.\n\nReference: https://scipy.github.io/devdocs/reference/generated/scipy.stats.tukey_hsd.html"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import tukey_hsd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load Experimental Data\n\nLoad the algorithm execution results from the Excel file containing performance metrics."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Read the experimental results\nexecutions = pd.read_excel(\"data/executions.xlsx\")\nexecutions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Group data by algorithm for comparative analysis\ntest_data = executions.groupby(\"algorithm\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract performance metrics for each algorithm\n# R_HV: Recall for Human Vehicles\n# R_AV: Recall for Autonomous Vehicles\n# R_W: Weighted Recall\nR_HV = {}\nR_AV = {}\nR_W = {}\nfor alg in executions[\"algorithm\"].unique():\n    R_HV[alg] = test_data.get_group(alg)[\"R_HV\"].values\n    R_AV[alg] = test_data.get_group(alg)[\"R_AV\"].values\n    R_W[alg] = test_data.get_group(alg)[\"R_W\"].values\n\nR_HV"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Statistical Testing: Tukey HSD and Kruskal-Wallis Test\n\n### Test Executions\n\n#### Human Vehicle (HV) Recall Analysis and Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Perform Tukey HSD test for all three metrics\n# This test determines which algorithm pairs have significantly different performance\nres_HV = tukey_hsd(R_HV[\"biLSTM\"], R_HV[\"Li_et_al + our features\"], R_HV[\"Li_et_al\"])\nres_AV = tukey_hsd(R_AV[\"biLSTM\"], R_AV[\"Li_et_al + our features\"], R_AV[\"Li_et_al\"])\nres_W = tukey_hsd(R_W[\"biLSTM\"], R_W[\"Li_et_al + our features\"], R_W[\"Li_et_al\"])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display p-values from Tukey HSD test for HV recall\n# Matrix showing pairwise comparison significance\nres_HV.pvalue"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test for pairwise algorithm comparisons\n",
    "# This non-parametric test is used when normality assumptions are not met\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "kruskal_results = pd.DataFrame(columns=[\"algorithm1\", \"algorithm2\", \"pvalue\"])\n",
    "\n",
    "stuff = [\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"]\n",
    "\n",
    "for num, subset in enumerate(itertools.combinations(stuff, 2)):\n",
    "    kruskal_results.loc[num] = [\n",
    "        subset[0],\n",
    "        subset[1],\n",
    "        stats.kruskal(R_HV[subset[0]], R_HV[subset[1]]).pvalue,\n",
    "    ]\n",
    "\n",
    "kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize HV recall distribution across algorithms using box plots\nimport seaborn as sns\nfrom statannotations.Annotator import Annotator\n\nalgorithms = np.unique(executions[\"algorithm\"])\n\nax = sns.boxplot(data=executions, x=\"algorithm\", y=\"R_HV\")\n\n# Define algorithm pairs for statistical annotation\npairs = [(i[1][\"algorithm1\"], i[1][\"algorithm2\"]) for i in kruskal_results.iterrows()]\np_values = [i[1][\"pvalue\"] for i in kruskal_results.iterrows()]\n\n# Set custom labels for better readability\nax.set_xticklabels([\"propoused\", \"Li_et_al + our features\", \"Li_et_al\"])\nax.set_ylabel(\"$\\overline{R_{HV}}$\")\n\n# Statistical annotations are commented out for cleaner visualization\n# annotator = Annotator(ax, pairs, data=executions, x=\"algorithm\", y=\"R_HV\")\n# annotator.configure(text_format=\"simple\", loc=\"inside\")\n# annotator.set_pvalues_and_annotate(p_values)\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Autonomous Vehicle (AV) Recall Analysis and Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test for AV recall metric\n",
    "import itertools\n",
    "\n",
    "kruskal_results = pd.DataFrame(columns=[\"algorithm1\", \"algorithm2\", \"pvalue\"])\n",
    "\n",
    "stuff = [\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"]\n",
    "\n",
    "for num, subset in enumerate(itertools.combinations(stuff, 2)):\n",
    "    kruskal_results.loc[num] = [\n",
    "        subset[0],\n",
    "        subset[1],\n",
    "        stats.kruskal(R_AV[subset[0]], R_AV[subset[1]]).pvalue,\n",
    "    ]\n",
    "\n",
    "kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize AV recall distribution across algorithms\nimport seaborn as sns\nfrom statannotations.Annotator import Annotator\n\nalgorithms = np.unique(executions[\"algorithm\"])\n\n# Create box plot without outliers for cleaner visualization\nax = sns.boxplot(data=executions, x=\"algorithm\", y=\"R_AV\", showfliers=False)\n\npairs = [(i[1][\"algorithm1\"], i[1][\"algorithm2\"]) for i in kruskal_results.iterrows()]\np_values = [i[1][\"pvalue\"] for i in kruskal_results.iterrows()]\n\nax.set_xticklabels([\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"])\nax.set_ylabel(\"Mean R_AV\")\n\n# Statistical annotations are commented out for cleaner visualization\n# annotator = Annotator(ax, pairs, data=executions, x=\"algorithm\", y=\"R_AV\")\n# annotator.configure(text_format=\"simple\", loc=\"inside\")\n# annotator.set_pvalues_and_annotate(p_values)\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Weighted Recall (W) Analysis and Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test for weighted recall metric\n",
    "import itertools\n",
    "\n",
    "kruskal_results = pd.DataFrame(columns=[\"algorithm1\", \"algorithm2\", \"pvalue\"])\n",
    "\n",
    "stuff = [\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"]\n",
    "\n",
    "for num, subset in enumerate(itertools.combinations(stuff, 2)):\n",
    "    kruskal_results.loc[num] = [\n",
    "        subset[0],\n",
    "        subset[1],\n",
    "        stats.kruskal(R_W[subset[0]], R_W[subset[1]]).pvalue,\n",
    "    ]\n",
    "\n",
    "kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-ready visualization for weighted recall\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# Define custom plot parameters for professional appearance\n",
    "custom_params = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"figure.figsize\": (12, 9),\n",
    "    \"text.color\": \"black\",\n",
    "    \"xtick.color\": \"black\",\n",
    "    \"ytick.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.labelcolor\": \"black\",\n",
    "}\n",
    "\n",
    "algorithms = np.unique(executions[\"algorithm\"])\n",
    "\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params, font=\"Times New Roman\", font_scale=2.7)\n",
    "\n",
    "ax = sns.boxplot(data=executions, x=\"algorithm\", y=\"R_W\")\n",
    "\n",
    "pairs = [(i[1][\"algorithm1\"], i[1][\"algorithm2\"]) for i in kruskal_results.iterrows()]\n",
    "p_values = [i[1][\"pvalue\"] for i in kruskal_results.iterrows()]\n",
    "\n",
    "ax.set_xticklabels([\"our\", \"Literature + our features\", \"Literature\"])\n",
    "ax.set_ylabel(\"$\\overline{R_{W}}$\")\n",
    "ax.set_xlabel(\"Algorithm\")\n",
    "\n",
    "# Save figure with transparent background for publication\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(f\"Rw_test.png\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Concept Drift Scenario Executions\n\n#### Human Vehicle (HV) Recall Analysis with Concept Drift"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract concept drift performance metrics (columns with .1 suffix)\n# These metrics evaluate algorithm performance under distribution shift conditions\nR_HV = {}\nR_AV = {}\nR_W = {}\nfor alg in executions[\"algorithm\"].unique():\n    R_HV[alg] = test_data.get_group(alg)[\"R_HV.1\"].values\n    R_AV[alg] = test_data.get_group(alg)[\"R_AV.1\"].values\n    R_W[alg] = test_data.get_group(alg)[\"R_W.1\"].values\n\nR_HV"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test for HV recall under concept drift conditions\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "kruskal_results = pd.DataFrame(columns=[\"algorithm1\", \"algorithm2\", \"pvalue\"])\n",
    "\n",
    "stuff = [\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"]\n",
    "\n",
    "for num, subset in enumerate(itertools.combinations(stuff, 2)):\n",
    "    kruskal_results.loc[num] = [\n",
    "        subset[0],\n",
    "        subset[1],\n",
    "        stats.kruskal(R_HV[subset[0]], R_HV[subset[1]]).pvalue,\n",
    "    ]\n",
    "\n",
    "kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize HV recall under concept drift conditions\nimport seaborn as sns\nfrom statannotations.Annotator import Annotator\n\nalgorithms = np.unique(executions[\"algorithm\"])\n\nax = sns.boxplot(data=executions, x=\"algorithm\", y=\"R_HV.1\")\n\npairs = [(i[1][\"algorithm1\"], i[1][\"algorithm2\"]) for i in kruskal_results.iterrows()]\np_values = [i[1][\"pvalue\"] for i in kruskal_results.iterrows()]\n\nax.set_xticklabels([\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"])\nax.set_ylabel(\"Mean R_HV\")\n\n# Statistical annotations are commented out for cleaner visualization\n# annotator = Annotator(ax, pairs, data=executions, x=\"algorithm\", y=\"R_HV.1\")\n# annotator.configure(text_format=\"simple\", loc=\"inside\")\n# annotator.set_pvalues_and_annotate(p_values)\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Autonomous Vehicle (AV) Recall Analysis with Concept Drift"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test for AV recall under concept drift conditions\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "kruskal_results = pd.DataFrame(columns=[\"algorithm1\", \"algorithm2\", \"pvalue\"])\n",
    "\n",
    "stuff = [\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"]\n",
    "\n",
    "for num, subset in enumerate(itertools.combinations(stuff, 2)):\n",
    "    kruskal_results.loc[num] = [\n",
    "        subset[0],\n",
    "        subset[1],\n",
    "        stats.kruskal(R_AV[subset[0]], R_AV[subset[1]]).pvalue,\n",
    "    ]\n",
    "\n",
    "kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize AV recall under concept drift conditions\nimport seaborn as sns\nfrom statannotations.Annotator import Annotator\n\nalgorithms = np.unique(executions[\"algorithm\"])\n\nax = sns.boxplot(data=executions, x=\"algorithm\", y=\"R_AV.1\")\n\npairs = [(i[1][\"algorithm1\"], i[1][\"algorithm2\"]) for i in kruskal_results.iterrows()]\np_values = [i[1][\"pvalue\"] for i in kruskal_results.iterrows()]\n\nax.set_xticklabels([\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"])\nax.set_ylabel(\"Mean R_AV\")\n\n# Statistical annotations are commented out for cleaner visualization\n# annotator = Annotator(ax, pairs, data=executions, x=\"algorithm\", y=\"R_AV.1\")\n# annotator.configure(text_format=\"simple\", loc=\"inside\")\n# annotator.set_pvalues_and_annotate(p_values)\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Weighted Recall (W) Analysis with Concept Drift"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test for weighted recall under concept drift conditions\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "kruskal_results = pd.DataFrame(columns=[\"algorithm1\", \"algorithm2\", \"pvalue\"])\n",
    "\n",
    "stuff = [\"biLSTM\", \"Li_et_al + our features\", \"Li_et_al\"]\n",
    "\n",
    "for num, subset in enumerate(itertools.combinations(stuff, 2)):\n",
    "    kruskal_results.loc[num] = [\n",
    "        subset[0],\n",
    "        subset[1],\n",
    "        stats.kruskal(R_W[subset[0]], R_W[subset[1]]).pvalue,\n",
    "    ]\n",
    "\n",
    "kruskal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-ready visualization for weighted recall under concept drift\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# Define custom plot parameters for professional appearance\n",
    "custom_params = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"figure.figsize\": (12, 9),\n",
    "    \"text.color\": \"black\",\n",
    "    \"xtick.color\": \"black\",\n",
    "    \"ytick.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.labelcolor\": \"black\",\n",
    "}\n",
    "\n",
    "algorithms = np.unique(executions[\"algorithm\"])\n",
    "\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params, font=\"Times New Roman\", font_scale=2.7)\n",
    "\n",
    "# Create box plot without outliers for cleaner visualization\n",
    "ax = sns.boxplot(data=executions, x=\"algorithm\", y=\"R_W.1\", showfliers=False)\n",
    "\n",
    "pairs = [(i[1][\"algorithm1\"], i[1][\"algorithm2\"]) for i in kruskal_results.iterrows()]\n",
    "p_values = [i[1][\"pvalue\"] for i in kruskal_results.iterrows()]\n",
    "\n",
    "ax.set_xticklabels([\"our\", \"Literature + our features\", \"Literature\"])\n",
    "ax.set_ylabel(\"$\\overline{R_{W}}$\")\n",
    "ax.set_xlabel(\"Algorithm\")\n",
    "\n",
    "# Save figure with transparent background for publication\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(f\"Rw_cd.png\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ACC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct  7 2022, 20:14:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad557be299645344835a0ba4d833676969f03c4a85c2833f5e1763ff6d83793b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}